{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, LSTM, BatchNormalization, LeakyReLU \n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Variables:\n",
    "How many batches? Try smaller batches if you're getting an OOM error.\n",
    "OOM = Out of Memory.\n",
    "SEQ_LEN = how long of a preceeding sequence to collect for RNN.\n",
    "Sequence Length is 60 mins long. \n",
    "EPOCHS = how many passes through our data.\n",
    "'''\n",
    "SEQ_LEN = 60\n",
    "FUTURE_PERIOD_PREDICT = 3\n",
    "# 1 period = 1 minute, eg 3 periods = 3 mins\n",
    "RATIO_TO_PREDICT = 'LTC-USD'\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64 \n",
    "NAME = f'{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Establishing a realtionship with the classify function. \n",
    "It states that if the future value that we are predicting is greater then the current value, \n",
    "then we want to indetify that future predicted value with a 1. \n",
    "If not, it will be assigned with a 0.\n",
    "'''\n",
    "def classify(current, future):\n",
    "    if float(future) > float(current):\n",
    "        return 1\n",
    "    else: \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess function\n",
    "'''\n",
    "def preprocess_df(df):\n",
    "    df = df.drop('future', 1)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col != 'target':\n",
    "            '''\n",
    "            Normalize the data\n",
    "            '''\n",
    "            df[col] = df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            '''\n",
    "            Scale the data\n",
    "            '''\n",
    "            df[col] = preprocessing.scale(df[col].values)\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    sequential_data = []\n",
    "    '''\n",
    "    As new data is added to this list (a max of 60 via SEQ_LEN), \n",
    "    deque will drop the old data\n",
    "    '''\n",
    "    prev_days = deque(maxlen=SEQ_LEN)\n",
    "    \n",
    "    for i in df.values:\n",
    "        '''\n",
    "        Appending each value in the lists of lists (each of the columns),\n",
    "        up to the last i, but not including our target feature.\n",
    "        '''\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days) == SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days), i[-1]])\n",
    "    \n",
    "    random.shuffle(sequential_data)\n",
    "    '''\n",
    "    Balance the data\n",
    "    '''\n",
    "    buys = []\n",
    "    sells = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        if target == 0:\n",
    "            sells.append([seq, target])\n",
    "        elif target == 1:\n",
    "            buys.append([seq, target])\n",
    "    \n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    '''    \n",
    "    what's that minimum of the two lists, buys and sells?\n",
    "    '''\n",
    "    lower = min(len(buys), len(sells))\n",
    "\n",
    "    buys = buys[:lower]\n",
    "    sells = sells[:lower]\n",
    "\n",
    "    sequential_data = buys+sells\n",
    "    random.shuffle(sequential_data)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for seq, target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    \n",
    "    return np.array(X), y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "\n",
    "names = ['time', 'low', 'high', 'open', 'close', 'volume']\n",
    "ratios = ['BTC-USD', 'LTC-USD', 'ETH-USD', 'BCH-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make new dataframe that incorporates all crypto currencies\n",
    "'''\n",
    "for ratio in ratios:\n",
    "    dataset = f'crypto_data/{ratio}.csv'\n",
    "\n",
    "    df = pd.read_csv(dataset, names=names)\n",
    "    df.rename(columns={'close': f'{ratio}_close', \n",
    "                       'volume': f'{ratio}_volume'}, \n",
    "                       inplace=True)\n",
    "\n",
    "    df.set_index('time', inplace=True)\n",
    "    df = df[[f'{ratio}_close', f'{ratio}_volume']]\n",
    "\n",
    "    if len(main_df) == 0:\n",
    "        main_df = df\n",
    "    else: \n",
    "        main_df = main_df.join(df)\n",
    "\n",
    "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
    "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 69188, val: 3062\n",
      "Dont buys: 34594, buys: 34594\n",
      "VALIDATION Dont buys: 1531, buys: 1531\n"
     ]
    }
   ],
   "source": [
    "times = sorted(main_df.index.values)\n",
    "last_5pct = times[-int(0.05*len(times))]\n",
    "\n",
    "val_main_df = main_df[(main_df.index >= last_5pct)]\n",
    "main_df = main_df[(main_df.index < last_5pct)]\n",
    "\n",
    "train_x, train_y, = preprocess_df(main_df)\n",
    "val_x, val_y = preprocess_df(val_main_df)\n",
    "\n",
    "'''\n",
    "Verify data split\n",
    "'''\n",
    "print(f'train data: {len(train_x)}, val: {len(val_x)}')\n",
    "print(f'Dont buys: {train_y.count(0)}, buys: {train_y.count(1)}')\n",
    "print(f'VALIDATION Dont buys: {val_y.count(0)}, buys: {val_y.count(1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reformat data\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "NN Architecture\n",
    "''' \n",
    "model = Sequential(name='Crypto_Model')\n",
    "\n",
    "model.add(Dense(128, input_shape=(train_x.shape[1:]), activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(128, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compile Model\n",
    "'''\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='nadam',\n",
    "              metrics=['acc', 'binary_crossentropy', 'cosine_proximity'])\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Unique file name that will include the epoch and\n",
    "the validation accuracy for that epoch.\n",
    "Checkpoint only saves the best ones.\n",
    "'''\n",
    "filepath = 'RNN_Final-{epoch:02d}-{val_acc:.3f}'\n",
    "checkpoint = ModelCheckpoint('models/{}.model'.format(filepath, \n",
    "                                                      monitor='val_acc', \n",
    "                                                      verbose=1, \n",
    "                                                      save_best_only=True, \n",
    "                                                      mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train the model\n",
    "'''\n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "val_x = np.asarray(val_x)\n",
    "val_y = np.asarray(val_y)\n",
    "\n",
    "history = model.fit(train_x, train_y,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(val_x, val_y),\n",
    "                    callbacks=[tensorboard, checkpoint])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('venv': venv)",
   "language": "python",
   "name": "python37464bitvenvvenv064d3c82b3934ee7a620a0d74d6d2ca9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
